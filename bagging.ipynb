{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitb881807a2701442397e35e3fb8dd8319",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "df = pd.read_csv('winequality-red.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:,'fixed acidity':'alcohol']\n",
    "\n",
    "scaler = StandardScaler().fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = (2, 5.5, 8)\n",
    "group_names = ['bad', 'good']\n",
    "df['quality'] = pd.cut(df['quality'], bins = bins, labels = group_names)\n",
    "label_quality = LabelEncoder()\n",
    "df['quality'] = label_quality.fit_transform(df['quality'])\n",
    "y = df['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Confusion matrix:\n[[114  35]\n [ 27 144]]\n\nAccuracy:\n0.80625\n              precision    recall  f1-score   support\n\n           0       0.81      0.77      0.79       149\n           1       0.80      0.84      0.82       171\n\n    accuracy                           0.81       320\n   macro avg       0.81      0.80      0.80       320\nweighted avg       0.81      0.81      0.81       320\n\n"
    }
   ],
   "source": [
    "#First we have implemented the BaggigngClassifier from sklearn without tuning the parameters.\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "b=BaggingClassifier()\n",
    "b.fit(X_train,y_train)\n",
    "pred = b.predict(X_test)\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(pred,y_test))\n",
    "print('\\nAccuracy:')\n",
    "print(accuracy_score(pred,y_test))\n",
    "print(classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'max_features': 8, 'n_estimators': 42}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As the only tweakable parameters of Bagging Classifier is max_features which needs to be considere and number of estimators that is the trees so we use GridSearch to estimate these parameters. With the features being 11 so we have kept the window between 1 and 10 with the number of trees between 40 and 50.\n",
    "parameter_candidates = {\n",
    "    'max_features' :list(range(1,10)),\n",
    "    'n_estimators': list(range(40,50))\n",
    "}\n",
    "\n",
    "grid_b = GridSearchCV(estimator = b, param_grid= parameter_candidates, scoring= 'accuracy', cv = 5)\n",
    "grid_b.fit(X_train, y_train)\n",
    "grid_b.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Confusion matrix:\n[[111  38]\n [ 30 141]]\n\nAccuracy:\n0.7875\n              precision    recall  f1-score   support\n\n           0       0.79      0.74      0.77       149\n           1       0.79      0.82      0.81       171\n\n    accuracy                           0.79       320\n   macro avg       0.79      0.78      0.79       320\nweighted avg       0.79      0.79      0.79       320\n\n"
    }
   ],
   "source": [
    "b1=BaggingClassifier(max_features=8, n_estimators=42)\n",
    "b1.fit(X_train,y_train)\n",
    "pred = b1.predict(X_test)\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(pred,y_test))\n",
    "print('\\nAccuracy:')\n",
    "print(accuracy_score(pred,y_test))\n",
    "print(classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}